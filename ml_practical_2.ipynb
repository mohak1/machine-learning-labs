{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml practical 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUsZwnkjsgbkP6wZ9awpja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohak1/machine-learning-labs/blob/main/ml_practical_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo3KsX4lMwbB"
      },
      "source": [
        "###2. Using Linear Regression from sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "V7Dq5YpK2KCe",
        "outputId": "275cbd5f-45bf-4ea3-f03b-1baf78969457"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#generate linearly predictable data using sklearn make regression\n",
        "X,Y = make_regression(n_samples=100, n_features=1, noise=3)\n",
        "\n",
        "#create a linear model\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2,random_state=0)\n",
        "\n",
        "#training the linear regression model\n",
        "linear_model.fit(x_train, y_train)\n",
        "\n",
        "#testing the performance of the trained model\n",
        "error = 0\n",
        "for i,data in enumerate(x_test):\n",
        "  data = np.reshape(data, (-1,1))\n",
        "  prediction = linear_model.predict(data)\n",
        "  #mean squared error\n",
        "  error += (prediction - y_test[i])**2\n",
        "print(f'the MSE of the linear model is {error/len(x_test)}')\n",
        "\n",
        "#plot the training & test set \n",
        "plt.scatter(x_train, y_train, color='blue')\n",
        "plt.scatter(x_test, y_test, color='orange')\n",
        "plt.scatter(x_test, linear_model.predict(np.reshape(x_test,(-1,1))), color='green')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the MSE of the linear model is [7.56484826]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1CLd0bPQUNx"
      },
      "source": [
        "###3. and 4. Gradient Descent without sklearn (single and multivariate)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6ADLQJ8xiCd"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "#generate single feature data\n",
        "X,Y = make_regression(n_samples=100, n_features=1, noise=3)\n",
        "\n",
        "#split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmXjKhD9OjYT"
      },
      "source": [
        "#define a model\n",
        "class my_regression_model:\n",
        "\n",
        "  def __init__(self, n_features=1):\n",
        "    #features=the no of features in the data\n",
        "    #create a dictionary to handle multiple weight vectors (when there are more features)\n",
        "    self.weight = {}\n",
        "    for i in range(n_features+1):\n",
        "      #name of this weight\n",
        "      weight_name = 'w'+str(i)\n",
        "      #add it to the weight dictionary and initialise it to zero (its a scalar)\n",
        "      self.weight[weight_name] = 0.0 \n",
        "    #print('self.weights at the end of init: ',self.weight)\n",
        "      \n",
        "\n",
        "  def model_output(self, feature):\n",
        "    #the model is of the form: w0 + w1x1 + w2x2 + ... + wnxn\n",
        "    no_of_weights = len(self.weight)\n",
        "    output_val = 0\n",
        "    for i in range(no_of_weights):\n",
        "      weight_name = 'w'+str(i)\n",
        "      if(weight_name=='w0'):\n",
        "        continue\n",
        "      weight = self.weight[weight_name]\n",
        "      #output_val = w1x1 + w2x2 + ... + wnxn\n",
        "      #print('value of i-1', i-1)\n",
        "      #print('value of feature: ', feature)\n",
        "      output_val += weight*feature[0][i-1]\n",
        "    #add w0 now\n",
        "    output_val += self.weight['w0']\n",
        "    return output_val\n",
        "\n",
        "\n",
        "  def update_weights(self, error, learning_rate, feature):\n",
        "    #for w0, update does not involve xi\n",
        "    no_of_weights = len(self.weight)\n",
        "    for i in range(no_of_weights):\n",
        "      weight_name = 'w'+str(i)\n",
        "      if(weight_name=='w0'):\n",
        "        self.weight[weight_name] += learning_rate*error\n",
        "      else:\n",
        "        self.weight[weight_name] += learning_rate*error*feature[i-1]\n",
        "\n",
        "\n",
        "  def train(self, train_x, train_y, batch_size=1, epochs=50, learning_rate=0.001):\n",
        "    for _ in range(epochs):\n",
        "      error=0\n",
        "      for i,x in enumerate(train_x):\n",
        "        #model output\n",
        "        x = np.reshape(x,(-1,len(x)))\n",
        "        output = self.model_output(x)\n",
        "        #accumulate the error  \n",
        "        error += train_y[i]-output\n",
        "        #forward pass until batch size, then back prop\n",
        "        if(i%batch_size==0):\n",
        "          self.update_weights(error, learning_rate, train_x[i])\n",
        "          error=0\n",
        "\n",
        "  def test(self, test_x, test_y):\n",
        "    mse_error = 0\n",
        "    #returns the list of model outputs for the entire input\n",
        "    for i,x in enumerate(test_x):\n",
        "      #model output\n",
        "      x = np.reshape(x,(-1,len(x)))\n",
        "      output = self.model_output(x)\n",
        "      mse_error += (output-test_y[i])**2\n",
        "    mse_error = mse_error/len(test_x)\n",
        "    return mse_error "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXwg_GZWxLsq",
        "outputId": "eba61a9f-cc30-4ef2-d439-7c065d736b9b"
      },
      "source": [
        "#using this model\n",
        "model = my_regression_model(n_features=1)\n",
        "model.train(x_train, y_train, batch_size=1, epochs=200, learning_rate=0.001)\n",
        "mse_error = model.test(x_test, y_test)\n",
        "print('Batch Size = 1; The mean squared error is: ', mse_error)\n",
        "\n",
        "model = my_regression_model(n_features=1)\n",
        "model.train(x_train, y_train, batch_size=2, epochs=500, learning_rate=0.01)\n",
        "mse_error = model.test(x_test, y_test)\n",
        "print('Batch Size = 2; The mean squared error is: ', mse_error)\n",
        "\n",
        "model = my_regression_model(n_features=1)\n",
        "model.train(x_train, y_train, batch_size=3, epochs=115, learning_rate=0.01)\n",
        "mse_error = model.test(x_test, y_test)\n",
        "print('Batch Size = 3; The mean squared error is: ', mse_error)\n",
        "\n",
        "model = my_regression_model(n_features=1)\n",
        "model.train(x_train, y_train, batch_size=4, epochs=115, learning_rate=0.01)\n",
        "mse_error = model.test(x_test, y_test)\n",
        "print('Batch Size = 4; The mean squared error is: ', mse_error)\n",
        "\n",
        "#works as good as sklearn regression model!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Size = 1; The mean squared error is:  13.070988993490605\n",
            "Batch Size = 2; The mean squared error is:  15.272330463146375\n",
            "Batch Size = 3; The mean squared error is:  13.01746524244469\n",
            "Batch Size = 4; The mean squared error is:  10.3882608716435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-Zp04IP_mwf"
      },
      "source": [
        "###Multivariate Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEoPTUol7ihR",
        "outputId": "278d0c59-1334-4ccc-8709-066d1a322c18"
      },
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "#generate single feature data\n",
        "X,Y = make_regression(n_samples=100, n_features=3, noise=3)\n",
        "\n",
        "#split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=0)\n",
        "\n",
        "#using this model\n",
        "model = my_regression_model(n_features=3)\n",
        "model.train(x_train, y_train, batch_size=1, epochs=100, learning_rate=0.01)\n",
        "mse_error = model.test(x_test, y_test)\n",
        "print('Batch Size = 1; The mean squared error is: ', mse_error)\n",
        "\n",
        "model = my_regression_model(n_features=3)\n",
        "model.train(x_train, y_train, batch_size=2, epochs=150, learning_rate=0.01)\n",
        "mse_error = model.test(x_test, y_test)\n",
        "print('Batch Size = 2; The mean squared error is: ', mse_error)\n",
        "\n",
        "model = my_regression_model(n_features=3)\n",
        "model.train(x_train, y_train, batch_size=3, epochs=300, learning_rate=0.01)\n",
        "mse_error = model.test(x_test, y_test)\n",
        "print('Batch Size = 3; The mean squared error is: ', mse_error)\n",
        "\n",
        "model = my_regression_model(n_features=3)\n",
        "model.train(x_train, y_train, batch_size=4, epochs=390, learning_rate=0.01)\n",
        "mse_error = model.test(x_test, y_test)\n",
        "print('Batch Size = 4; The mean squared error is: ', mse_error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch Size = 1; The mean squared error is:  9.430947342993719\n",
            "Batch Size = 2; The mean squared error is:  9.597211738217364\n",
            "Batch Size = 3; The mean squared error is:  20.86717801689047\n",
            "Batch Size = 4; The mean squared error is:  7.086688653590917e+18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEjoTA4VDql1"
      },
      "source": [
        "###5. More: Ensemble of trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVKHmMuYDtNB",
        "outputId": "7141f599-eb2f-404d-bd99-9d245f21c3cc"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from statistics import mode\n",
        "\n",
        "bc = load_breast_cancer()\n",
        "X = bc.data\n",
        "Y = bc.target\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.20, random_state=0)\n",
        "\n",
        "#train 5 trees and ensemble them\n",
        "tree1 = DecisionTreeClassifier().fit(x_train,y_train)\n",
        "score1 = tree1.score(x_test, y_test)\n",
        "\n",
        "tree2 = DecisionTreeClassifier().fit(x_train,y_train)\n",
        "score2 = tree2.score(x_test, y_test)\n",
        "\n",
        "tree3 = DecisionTreeClassifier().fit(x_train,y_train)\n",
        "score3 = tree3.score(x_test, y_test)\n",
        "\n",
        "tree4 = DecisionTreeClassifier().fit(x_train,y_train)\n",
        "score4 = tree4.score(x_test, y_test)\n",
        "\n",
        "tree5 = DecisionTreeClassifier().fit(x_train,y_train)\n",
        "score5 = tree5.score(x_test, y_test)\n",
        "\n",
        "print('individual score of the trees are: ',score1,score2,score3,score4,score5)\n",
        "\n",
        "#ensemble\n",
        "outs = []\n",
        "final_output = []\n",
        "for i, x in enumerate(x_test):\n",
        "  x = np.reshape(x, (1,-1))\n",
        "  outs.append(tree1.predict(x)[0])\n",
        "  outs.append(tree2.predict(x)[0])\n",
        "  outs.append(tree3.predict(x)[0])\n",
        "  outs.append(tree4.predict(x)[0])\n",
        "  outs.append(tree5.predict(x)[0])\n",
        "  mode_output = mode(outs)\n",
        "  final_output.append(mode_output)\n",
        "  outs = []\n",
        "\n",
        "#get the score of the ensemble model\n",
        "correct = 0\n",
        "for i in range(len(x_test)):\n",
        "  if(final_output[i]==y_test[i]):\n",
        "    correct += 1\n",
        "accuracy = (correct/len(x_test))*100\n",
        "print('score of the ensemble tree', accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "individual score of the trees are:  0.8947368421052632 0.9122807017543859 0.9122807017543859 0.9035087719298246 0.9035087719298246\n",
            "score of the ensemble tree 90.35087719298247\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}